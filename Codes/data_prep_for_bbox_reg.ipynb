{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from shutil import copyfile\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from xml.etree import ElementTree\n",
    "import glob\n",
    "import os.path, time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "from random import sample, choices\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "plt.rcParams[\"figure.figsize\"] = [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base path for xml\n",
    "xml_base_path = \"/home/ved/ved/Annotations/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_base_path = \"/home/ved/ved/Images/Shoes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation files\n",
    "os.chdir(xml_base_path)\n",
    "annotation_files = os.listdir(xml_base_path )\n",
    "annotation_file_names =[i.split(\"\\\\\")[-1].split(\".\")[0] for i in annotation_files]\n",
    "annotation_file_names = [i for i in annotation_file_names if len(i) !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skechers-work-holdredge-black-action-leather-trim_product_8861515_color_680937',\n",
       " 'lowa-zephyr-gtx-mid-tf-wolf-grey_product_8575700_color_219303',\n",
       " 'georgia-boot-g5153-12-wellington-barracuda-gold_product_121847_color_584864',\n",
       " 'nike-free-rn-2018-gym-red-bright-crimson-black-team-red_product_8982513_color_748881',\n",
       " 'franco-sarto-orchard-black-bally-leather_product_9197825_color_711287']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4756"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotation_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dim(name):\n",
    "    name = name\n",
    "    xml_path = xml_base_path + name + \".xml\"\n",
    "    img = plt.imread(images_base_path  +name + \".jpg\")\n",
    "    soup = BeautifulSoup(open(xml_path).read())\n",
    "    x_dim = img.shape[1]\n",
    "    y_dim = img.shape[0]\n",
    "    x_xml = soup.find_all([\"x\",\"xmin\",\"xmax\"])\n",
    "    y_xml = soup.find_all([\"y\",\"ymin\",\"ymax\"])\n",
    "    x_txt = [float(i.text) for i in x_xml]\n",
    "    y_txt = [float(i.text) for i in y_xml]\n",
    "    ind_x = sum([i for i in x_txt if i > x_dim])\n",
    "    ind_y = sum([i for i in y_txt if i > y_dim])\n",
    "    if ((ind_x > 0) or (ind_y >0)):\n",
    "        return \"nf\"\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=47)]: Using backend ThreadingBackend with 47 concurrent workers.\n",
      "[Parallel(n_jobs=47)]: Done   4 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=47)]: Done  19 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=47)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=47)]: Done  51 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=47)]: Done  68 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=47)]: Done  87 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=47)]: Done 106 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=47)]: Done 127 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=47)]: Done 148 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=47)]: Done 171 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=47)]: Done 194 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=47)]: Done 219 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=47)]: Done 244 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=47)]: Done 271 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=47)]: Done 298 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=47)]: Done 327 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=47)]: Done 356 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=47)]: Done 387 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=47)]: Done 418 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=47)]: Done 451 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=47)]: Done 484 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=47)]: Done 519 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=47)]: Done 554 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=47)]: Done 591 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=47)]: Done 628 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=47)]: Done 667 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=47)]: Done 706 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=47)]: Done 747 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=47)]: Done 788 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=47)]: Done 831 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=47)]: Done 874 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=47)]: Done 919 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=47)]: Done 964 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=47)]: Done 1011 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=47)]: Done 1058 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=47)]: Done 1107 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=47)]: Done 1156 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=47)]: Done 1207 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=47)]: Done 1258 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=47)]: Done 1311 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=47)]: Done 1364 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=47)]: Done 1419 tasks      | elapsed:   59.9s\n",
      "[Parallel(n_jobs=47)]: Done 1474 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=47)]: Done 1531 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=47)]: Done 1588 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=47)]: Done 1647 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=47)]: Done 1706 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=47)]: Done 1767 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=47)]: Done 1828 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=47)]: Done 1891 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=47)]: Done 1954 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=47)]: Done 2019 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=47)]: Done 2084 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=47)]: Done 2151 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=47)]: Done 2218 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=47)]: Done 2287 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=47)]: Done 2356 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=47)]: Done 2427 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=47)]: Done 2498 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=47)]: Done 2571 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=47)]: Done 2644 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=47)]: Done 2719 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=47)]: Done 2794 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=47)]: Done 2871 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=47)]: Done 2948 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=47)]: Done 3027 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=47)]: Done 3106 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=47)]: Done 3187 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=47)]: Done 3268 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=47)]: Done 3351 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=47)]: Done 3434 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=47)]: Done 3519 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=47)]: Done 3604 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=47)]: Done 3691 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=47)]: Done 3778 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=47)]: Done 3867 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=47)]: Done 3956 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=47)]: Done 4047 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=47)]: Done 4138 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=47)]: Done 4231 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=47)]: Done 4324 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=47)]: Done 4419 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=47)]: Done 4514 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=47)]: Done 4611 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=47)]: Done 4756 out of 4756 | elapsed:  3.2min finished\n"
     ]
    }
   ],
   "source": [
    "# uncomment to get data\n",
    "catch_images_shoes = Parallel(n_jobs=47, verbose = 10, backend = \"threading\")(delayed(check_dim)(file) for file in annotation_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_correct = [i for i in catch_images_shoes if i !=\"nf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41181416859365144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in paths_correct])/len(annotation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xmls(name): \n",
    "    # read the file name\n",
    "    xml_path =  xml_base_path + name + \".xml\"\n",
    "    img = plt.imread(images_base_path  +name + \".jpg\")\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    # make soup\n",
    "    # pass the path to the beautiful soup function\n",
    "    soup = BeautifulSoup(open(xml_path).read())\n",
    "    soup_obj = soup.find_all(\"object\")\n",
    "    catch = []\n",
    "    for item in range(len(soup_obj)):\n",
    "        class_name = soup_obj[item].find_all(\"name\")[0].text\n",
    "        x_pts = [int(round(float(i.text),0)) for i in soup_obj[item].find_all([\"x\",\"xmin\",\"xmax\"])]\n",
    "        y_pts = [int(round(float(i.text),0)) for i in soup_obj[item].find_all([\"y\",\"ymin\",\"ymax\"])]\n",
    "        xmin = np.min(x_pts)\n",
    "        ymin = np.min(y_pts)\n",
    "        xmax = np.max(x_pts)\n",
    "        ymax = np.max(y_pts)\n",
    "        catch_obj = {\"class\": class_name, \"xmin\":xmin, \"ymin\":ymin,\"xmax\":xmax,\"ymax\":ymax}\n",
    "        catch_obj[\"filename\"] = name + \".jpg\"\n",
    "        catch_obj[\"width\"] = width\n",
    "        catch_obj[\"height\"] = height\n",
    "        catch.append(catch_obj)\n",
    "    return(catch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=47)]: Using backend ThreadingBackend with 47 concurrent workers.\n",
      "[Parallel(n_jobs=47)]: Done   4 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=47)]: Done  19 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=47)]: Done  34 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=47)]: Done  51 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=47)]: Done  68 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=47)]: Done  87 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=47)]: Done 106 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=47)]: Done 127 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=47)]: Done 148 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=47)]: Done 171 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=47)]: Done 194 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=47)]: Done 219 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=47)]: Done 244 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=47)]: Done 271 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=47)]: Done 298 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=47)]: Done 327 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=47)]: Done 356 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=47)]: Done 387 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=47)]: Done 418 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=47)]: Done 451 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=47)]: Done 484 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=47)]: Done 519 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=47)]: Done 554 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=47)]: Done 591 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=47)]: Done 628 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=47)]: Done 667 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=47)]: Done 706 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=47)]: Done 747 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=47)]: Done 788 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=47)]: Done 831 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=47)]: Done 874 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=47)]: Done 919 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=47)]: Done 964 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=47)]: Done 1011 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=47)]: Done 1058 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=47)]: Done 1107 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=47)]: Done 1156 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=47)]: Done 1207 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=47)]: Done 1258 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=47)]: Done 1311 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=47)]: Done 1364 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=47)]: Done 1419 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=47)]: Done 1474 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=47)]: Done 1531 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=47)]: Done 1588 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=47)]: Done 1647 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=47)]: Done 1706 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=47)]: Done 1767 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=47)]: Done 1828 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=47)]: Done 1959 out of 1959 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "# uncomment to get data\n",
    "catch_images_shoes = Parallel(n_jobs=47, verbose = 10, backend = \"threading\")(delayed(parse_xmls)(file) for file in paths_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to get data\n",
    "catch_images_shoes = [j for i in catch_images_shoes for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to get data\n",
    "catch_images_shoes_df = pd.DataFrame(catch_images_shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_images_shoes_df = pd.DataFrame(catch_images_shoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_images_shoes_df.to_csv(\"/home/ved/ved/Data/shoe_annotations.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exclude</td>\n",
       "      <td>274</td>\n",
       "      <td>640</td>\n",
       "      <td>1049</td>\n",
       "      <td>765</td>\n",
       "      <td>skechers-work-holdredge-black-action-leather-t...</td>\n",
       "      <td>1908</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exclude</td>\n",
       "      <td>663</td>\n",
       "      <td>82</td>\n",
       "      <td>1092</td>\n",
       "      <td>194</td>\n",
       "      <td>skechers-work-holdredge-black-action-leather-t...</td>\n",
       "      <td>1908</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quadrilateral</td>\n",
       "      <td>99</td>\n",
       "      <td>276</td>\n",
       "      <td>298</td>\n",
       "      <td>465</td>\n",
       "      <td>skechers-work-holdredge-black-action-leather-t...</td>\n",
       "      <td>1908</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quadrilateral</td>\n",
       "      <td>309</td>\n",
       "      <td>177</td>\n",
       "      <td>497</td>\n",
       "      <td>367</td>\n",
       "      <td>skechers-work-holdredge-black-action-leather-t...</td>\n",
       "      <td>1908</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quadrilateral</td>\n",
       "      <td>312</td>\n",
       "      <td>374</td>\n",
       "      <td>502</td>\n",
       "      <td>557</td>\n",
       "      <td>skechers-work-holdredge-black-action-leather-t...</td>\n",
       "      <td>1908</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  xmin  ymin  xmax  ymax  \\\n",
       "0        exclude   274   640  1049   765   \n",
       "1        exclude   663    82  1092   194   \n",
       "2  quadrilateral    99   276   298   465   \n",
       "3  quadrilateral   309   177   497   367   \n",
       "4  quadrilateral   312   374   502   557   \n",
       "\n",
       "                                            filename  width  height  \n",
       "0  skechers-work-holdredge-black-action-leather-t...   1908     777  \n",
       "1  skechers-work-holdredge-black-action-leather-t...   1908     777  \n",
       "2  skechers-work-holdredge-black-action-leather-t...   1908     777  \n",
       "3  skechers-work-holdredge-black-action-leather-t...   1908     777  \n",
       "4  skechers-work-holdredge-black-action-leather-t...   1908     777  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catch_images_shoes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = np.unique(catch_images_shoes_df[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1958"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to get all the region proposals\n",
    "\n",
    "def get_rpn(filename,method = \"quality\"): \n",
    "    base_path = images_base_path\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "#     base_path = r\"D:\\Shoes\\Shoes_with_annotations\\\\\"\n",
    "    filename = filename\n",
    "    samp_path = base_path + filename\n",
    "    im = cv2.imread(samp_path)\n",
    "    ss.setBaseImage(im)\n",
    "    if method == \"fast\":\n",
    "        print(method)\n",
    "        ss.switchToSelectiveSearchFast()\n",
    "    if method == \"quality\":\n",
    "        print(method)\n",
    "        ss.switchToSelectiveSearchQuality()\n",
    "    rects = ss.process()\n",
    "    coords = []\n",
    "    for (x, y, w, h) in rects: \n",
    "        xmin, ymin, xmax, ymax = x,y,x+w, y+h\n",
    "        coords.append([xmin, ymin, xmax, ymax])\n",
    "    return(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to get all the region proposals\n",
    "\n",
    "def get_rpn_df(filename,method = \"fast\"):\n",
    "#     store_path = r\"D:\\Shoes\\Latest_Iteration\\Robot_Annotated\\\\\"\n",
    "    base_path = images_base_path\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "#     base_path = base_path\n",
    "    filename = filename\n",
    "    samp_path = base_path + filename\n",
    "    temp_data = catch_images_shoes_df[catch_images_shoes_df[\"filename\"] == filename]\n",
    "    temp_data = temp_data[temp_data[\"class\"] != \"exclude\"]\n",
    "    im = cv2.imread(samp_path)\n",
    "    ss.setBaseImage(im)\n",
    "    if method == \"fast\":\n",
    "#         print(method)\n",
    "        ss.switchToSelectiveSearchFast()\n",
    "    if method == \"quality\":\n",
    "#         print(method)\n",
    "        ss.switchToSelectiveSearchQuality()\n",
    "    rects = ss.process()\n",
    "    coords = []\n",
    "    for (x, y, w, h) in rects: \n",
    "        xmin, ymin, xmax, ymax = x,y,x+w, y+h\n",
    "        coords.append([xmin, ymin, xmax, ymax])\n",
    "    robot_dict = []\n",
    "    for i in coords:\n",
    "        human_annotated_dict = {\"x1\": i[0], \"x2\": i[2], \n",
    "                       \"y1\": i[1],\"y2\": i[3]}\n",
    "        robot_dict.append(human_annotated_dict)\n",
    "    best_catches = []\n",
    "    max_value_catch = []\n",
    "    for i in temp_data.values:\n",
    "        class_name = i[0]\n",
    "        human_annotated = i[1:5]\n",
    "        filename = i[5]\n",
    "        width, height = i[6], i[7]\n",
    "        human_annotated_dict = {\"x1\": human_annotated[0], \"x2\": human_annotated[2], \n",
    "                       \"y1\": human_annotated[1],\"y2\": human_annotated[3]}\n",
    "        iou_human_vs_robot = [get_iou(n,human_annotated_dict) for i,n in enumerate(robot_dict)]\n",
    "    \n",
    "        suitable_indexes = [i for i,n in enumerate(iou_human_vs_robot) if n > 0.6]\n",
    "    \n",
    "        # get those rpns\n",
    "    \n",
    "        rpn_values = [robot_dict[i] for i  in suitable_indexes]\n",
    "    \n",
    "        iou_values = [iou_human_vs_robot[i] for i in suitable_indexes]\n",
    "    \n",
    "#     max_value = np.max(iou_human_vs_robot)\n",
    "#     max_value_catch.append(max_value)\n",
    "#     best_rpn = robot_dict[np.argmax(iou_human_vs_robot)]\n",
    "    \n",
    "        for i,n in enumerate(rpn_values): \n",
    "            best_rpn = n\n",
    "            xmin, ymin, xmax, ymax = best_rpn[\"x1\"], best_rpn[\"y1\"], best_rpn[\"x2\"], best_rpn[\"y2\"]\n",
    "            obj = [xmin, ymin, xmax, ymax]\n",
    "            dict1 = {\"human_rpn\": human_annotated, \"ss_rpn\": obj, \"iou\": iou_values[i], \"class\":class_name,\n",
    "                \"filename\": filename, \"width\":width, \"height\":height}\n",
    "            best_catches.append(dict1)\n",
    "#     mean_iou = np.mean(max_value_catch)\n",
    "#     counter = 0\n",
    "#     output = im.copy()\n",
    "#     for i1 in range(0, len(best_catches)):\n",
    "#         counter = counter + 1\n",
    "#     # clone the original image so we can draw on it\n",
    "    \n",
    "    \n",
    "#     # loop over the current subset of region proposals\n",
    "#         i = best_catches[i1]\n",
    "    \n",
    "#         xmin = i[0]\n",
    "#         ymin = i[1]\n",
    "#         xmax = i[2]\n",
    "#         ymax = i[3]\n",
    "#     # draw the region proposal bounding box on the image\n",
    "# #     color = [random.randint(0, 255) for j in range(0, 3)]\n",
    "#         cv2.rectangle(output, (xmin, ymin), (xmax, ymax), (0,0,255), 3)\n",
    "#     plt.imsave(store_path + filename,output[:,:,::-1])\n",
    "    return(best_catches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=47)]: Using backend ThreadingBackend with 47 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "rpn_df = Parallel(n_jobs=47, verbose = 10, backend = \"threading\")(delayed(get_rpn_df)(file) for file in file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ved/ved/Data/bbox_regression_list.pickle', 'wb') as b:\n",
    "    pickle.dump(rpn_df,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/ved/ved/Data/blah.pickle', \"rb\") as input_file:\n",
    "#     e = pickle.load(input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
